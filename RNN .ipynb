{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#import cientifico de operação\n",
    "import numpy as np\n",
    "#tratamento de Imagem\n",
    "from PIL import Image\n",
    "#import para plotagem dos graficos e etc\n",
    "import matplotlib \n",
    "#import para DeepLearnin Rnn e o krl a 4\n",
    "import tensorflow \n",
    "from keras.models import Sequential, model_from_json, Model\n",
    "from keras.layers import MaxPooling2D, Embedding, BatchNormalization\n",
    "from keras.layers import Convolution2D, Dense, Dropout, InputLayer, Flatten, LSTM, Input, concatenate\n",
    "from keras.layers.merge import concatenate\n",
    "#modelos\n",
    "import h5py\n",
    "#importação para a merda do diretorio\n",
    "import os\n",
    "from os import listdir\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = 12\n",
    "batch_size = 32\n",
    "train = 'data/train/'\n",
    "teste = 'data/teste/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rotation_range=40,#rotação na imagem\n",
    "                                   rescale=1./255,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,#zoom\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(directory=train,\n",
    "                                                    target_size=[100, 100],\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='binary',\n",
    "                                                    follow_links=True)\n",
    "\n",
    "validation_datagen = ImageDataGenerator()\n",
    "validation_generator = validation_datagen.flow_from_directory(directory=teste,\n",
    "                                                              target_size=[100, 100],\n",
    "                                                              batch_size=batch_size,\n",
    "                                                              class_mode='binary',\n",
    "                                                              follow_links=True, \n",
    "                                                              shuffle=False)\n",
    "\n",
    "x_train,y_train=train_generator.next()\n",
    "x_teste, y_teste=validation_generator.next()\n",
    "np.shape(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convolução\n",
    "classifier = Sequential()\n",
    "\n",
    "#Entrada\n",
    "#classifier.add(InputLayer(input_shape=(100, 100, 3)))\n",
    "classifier.add(Convolution2D(32,3,3, input_shape = (100,100,3), activation ='tanh'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2), input_shape = (100,100,3)))\n",
    "classifier.add(Dropout(0.2))\n",
    "#layers 1\n",
    "classifier.add(Convolution2D(64,3,3, activation = 'tanh'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2), input_shape = (100,100,3)))\n",
    "classifier.add(Dropout(0.1))\n",
    "#layers 2\n",
    "classifier.add(Convolution2D(128,3,3,  activation = 'tanh'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2), input_shape = (100,100,3)))\n",
    "classifier.add(Dropout(0.2))\n",
    "#layers 3\n",
    "classifier.add(Convolution2D(256,3,3,  activation = 'tanh'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2), input_shape = (100,100,3)))\n",
    "classifier.add(Dropout(0.2))\n",
    "classifier.add(Flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saida\n",
    "classifier.add(Dense(units = 8196, activation = 'tanh'))\n",
    "classifier.add(Dropout(rate = 0.2))\n",
    "classifier.add(Dense(1, activation = 'sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_input = Input(shape=(100, 100, 3))\n",
    "encoded_image = classifier(image_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_input = Input(shape=(100,), dtype='int32')\n",
    "embedded_question = Embedding(input_dim=10000, output_dim=100, input_length=100)(question_input)\n",
    "encoded_question = LSTM(256)(embedded_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = concatenate([encoded_question, encoded_image])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(loss=['binary_crossentropy'], optimizer='Adam', metrics=['accuracy', 'mae', 'categorical_accuracy', 'binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=classifier.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=500,\n",
    "        epochs=50,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = classifier.to_json()\n",
    "with open(\"model/modelo_.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "classifier.save_weights('model/modelo_.h5')  \n",
    "classifier.save('model/modelo_.h5')\n",
    "classes = train_generator.class_indices\n",
    "print(classes)\n",
    "print(\"Modelo Salvo com sucesso!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Treinamento')\n",
    "plt.ylabel('precisão')\n",
    "plt.xlabel('Epoca')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "  \n",
    "plt.plot(history.history['val_mean_absolute_error'])\n",
    "plt.plot(history.history['mean_absolute_error'])\n",
    " \n",
    "plt.title('Treinamento usando a métrica de erro absoluto')\n",
    "plt.ylabel('Mean_absolute error')\n",
    "plt.xlabel('Epoca')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['binary_accuracy'])\n",
    "plt.plot(history.history['val_binary_accuracy'])\n",
    "plt.title('Treinamento usando a métrica binaria')\n",
    "plt.ylabel('binary_accuracy')\n",
    "plt.xlabel('Epoca')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.plot(history.history['val_categorical_accuracy'])    \n",
    "plt.title('Treinamento usando a métrica de categoria')\n",
    "plt.ylabel('categorical_accuracy')\n",
    "plt.xlabel('Epoca')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
